:PROPERTIES:
:ID:       1d1078cc-7427-4ccf-9de5-af2bf8a064fb
:header-args:python: :results output
:END:
#+title: pytorch-Tensor
#+date: [2024-05-12 日]
#+last_modified: [2024-05-15 三 23:14]




* 创建张量

** 从Python 类型创建
#+begin_src python 
  import torch

  x1 = [1, 2, 3]
  x1_tensor = torch.tensor(x1, dtype=torch.int32)
  
  print(x1_tensor)
#+end_src

#+RESULTS:
: tensor([1, 2, 3], dtype=torch.int32)


从 torch.Tensor 构建默认是 torch.float32 类型
#+begin_src python 
  import torch

  x1 = [1, 2, 3]
  x1_tensor = torch.Tensor(x1)
  
  print(x1_tensor)
#+end_src

#+RESULTS:
: tensor([1., 2., 3.])


** 从 numpy类型创建

#+begin_src python
  import numpy as np
  import torch

  x2_numpy = np.array( [1, 2, 3])
  x2_tensor = torch.from_numpy(x2_numpy)
  
  print(x2_tensor)
#+end_src

#+RESULTS:
: tensor([1, 2, 3])

*** torch.Tensor 转 Numpy
#+begin_src python
  import torch
  import numpy as np
  # 创建一个 numpy ndarray
  numpy_tensor = np.random.randn(10, 20)
  pytorch_tensor1 = torch.Tensor(numpy_tensor)

  # 如果 pytorch tensor 在 cpu 上
  numpy_array = pytorch_tensor1.numpy()

  # 如果 pytorch tensor 在 gpu 上
  # numpy_array = pytorch_tensor1.cpu().numpy()

  print(numpy_array[0])
#+end_src

#+RESULTS:
: [ 0.43122151  1.2320664   1.9012676  -0.85511     1.0127811  -0.12148461
:   0.6159392  -0.30144146 -0.41885114 -2.2313313  -0.2793571   1.1048236
:   0.02130411  0.11283709  1.8216728  -1.2150816   0.47295213 -1.112893
:  -0.9163593   1.2060593 ]




** 从已有的 torch.Tensor 创建

#+begin_src python
  import numpy as np
  import torch

  x2_numpy = np.array( [1, 2, 3])
  x2_tensor = torch.from_numpy(x2_numpy)

  x3_tensor = torch.ones_like(x2_tensor)
  print(x3_tensor)
#+end_src

#+RESULTS:
: tensor([1, 1, 1])


** 创建高斯分布张量


#+begin_src python
  import torch
  
  size = [1, 3]
  x4_tensor = torch.randn(size)
  print(x4_tensor)
#+end_src

#+RESULTS:
: tensor([[-0.4661, -0.0289, -0.9740]])


** 创建零张量
#+begin_src python
  import torch
  
  size = [1, 3]
  x5_tensor = torch.zeros(size)
  print(x5_tensor)
#+end_src

#+RESULTS:
: tensor([[0., 0., 0.]])

* 张量类型转换

#+begin_src python 
  import torch

  x1 = [1, 2, 3]
  x1_tensor = torch.tensor(x1, dtype=torch.int32)

  print("1>>dtype: ", x1_tensor.dtype)

  x1_tensor = x1_tensor.float()
  print("2>>dtype: ", x1_tensor.dtype)

  x1_tensor = x1_tensor.double()
  print("3>>dtype: ", x1_tensor.dtype)

  
  x1_tensor = x1_tensor.int()
  print("4>>dtype: ", x1_tensor.dtype)
#+end_src

#+RESULTS:
: 1>>dtype:  torch.int32
: 2>>dtype:  torch.float32
: 3>>dtype:  torch.float64
: 4>>dtype:  torch.int32
#+end_src

#+RESULTS:
: 1>>dtype:  torch.int32
: 2>>dtype:  torch.float32
: 3>>dtype:  torch.float64


* 张量形状操作

** 获取张量形状
#+begin_src python 
  import torch

  x = torch.rand(1, 3, 4, 4)


  print("ndimension: ", x.ndimension())
  print("nelement: ", x.nelement())
  print("size: ", x.size())
  print("shape: ", x.shape)
#+end_src

#+RESULTS:
: ndimension:  4
: nelement:  48
: size:  torch.Size([1, 3, 4, 4])
: shape:  torch.Size([1, 3, 4, 4])

** 修改张量形状
#+begin_src python 
  import torch

  x = torch.rand(1, 3, 4, 4)

  x_view = x.view(1, 3, 4*4)
  print("1x_view: ", x_view.size())

  x_view = x.view(1, -1)
  print("2x_view: ", x_view.size())
#+end_src

#+RESULTS:
: 1x_view:  torch.Size([1, 3, 16])
: 2x_view:  torch.Size([1, 48])

*** 转置

#+begin_src python 
  import torch

  x = torch.rand(2, 3)
  print(x)
  
  x_trans = x.transpose(1, 0)
  print(x_trans)
#+end_src

#+RESULTS:
: tensor([[0.4236, 0.7654, 0.9085],
:         [0.4364, 0.0288, 0.2000]])
: tensor([[0.4236, 0.4364],
:         [0.7654, 0.0288],
:         [0.9085, 0.2000]])

** 维度压缩

#+begin_src python 
  import torch

  x = torch.rand(1, 3, 4, 4)
  x = x.squeeze(0)
  print(x.size())

  x = x.unsqueeze(0)
  print(x.size())
#+end_src

#+RESULTS:
: torch.Size([3, 4, 4])
: torch.Size([1, 3, 4, 4])



* 原型和子视图

#+begin_src python
  import torch

  x = torch.tensor([1, 2])
  y = torch.tensor([1, 2])

  s = x.clone()
  t = x.detach()

  print("X: ", x.data_ptr())
  print("Y: ", y.data_ptr())
  print("S: ", s.data_ptr())
  print("T: ", t.data_ptr())
#+end_src

#+RESULTS:
: X:  106173376
: Y:  106173504
: S:  106207296
: T:  106173376

* 切片


#+begin_src python
  import torch

  x = torch.tensor([1, 2, 3, 4, 5])

  print(x[1:3])
  print(x[:])
  print(x[-1])
#+end_src

#+RESULTS:
: tensor([2, 3])
: tensor([1, 2, 3, 4, 5])
: tensor(5)


* 拼接

#+begin_src python
  import torch

  x = torch.tensor([1, 2, 3])
  y = torch.tensor([4, 5, 6])
  z = torch.tensor([7, 8, 9])

  q = torch.cat(tensors=(x, y, z), dim=0)
  print(q)
#+end_src

#+RESULTS:
: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])


* 四则运算
另外，pytorch中大多数的操作都支持 inplace 操作，也就是可以直接对 tensor 进行操作而不需要另外开辟内存空间，
方式非常简单，一般都是在操作的符号后面加_

#+begin_src python
  import torch

  x1 = torch.tensor([[1, 2],
		     [3, 4]])
  x2 = torch.tensor([[1, 2],
		     [3, 4]])

  print(torch.add(x1, x2))
  print(torch.sub(x1, x2))
  print("------------")

  print(x1.add_(x2))
  print(x1.sub_(x2))
  print("------------")

  print(x1+x2)
  print(x1-x2)
  print(x1*x2)
  print(x1/x2)
  print("------------")

  print(torch.mul(x1, x2))
#+end_src

#+RESULTS:
#+begin_example
tensor([[2, 4],
        [6, 8]])
tensor([[0, 0],
        [0, 0]])
------------
tensor([[2, 4],
        [6, 8]])
tensor([[1, 2],
        [3, 4]])
------------
tensor([[2, 4],
        [6, 8]])
tensor([[0, 0],
        [0, 0]])
tensor([[ 1,  4],
        [ 9, 16]])
tensor([[1., 1.],
        [1., 1.]])
------------
tensor([[ 1,  4],
        [ 9, 16]])
#+end_example


* 矩阵乘法

#+begin_src python
  import torch

  x1 = torch.tensor([[1, 2],
		     [3, 4]])
  x2 = torch.tensor([[1, 2],
		     [3, 4]])


  print(torch.mm(x1, x2))
#+end_src

#+RESULTS:
: tensor([[ 7, 10],
:         [15, 22]])


* 其他

#+begin_src python
  import torch

  x = torch.randn(1,2,3)

  max_value, max_idx = torch.max(x, dim=1)

  print("Max value: " , max_value , " idx: " , max_idx)

  sum_x = torch.sum(x, dim=1)
  print("Sum value: " , sum_x)

  x = x.permute(1, 0, 2) # permute 可以重新排列 tensor 的维度
  print(x.shape)

  x = x.view(-1, 2) # -1 表示任意的大小，5 表示第二维变成 5
  print(x.shape)

  x = x.view(2, 3) 
  print(x.shape)
#+end_src

#+RESULTS:
: Max value:  tensor([[ 1.1215,  1.1252, -0.4461]])  idx:  tensor([[1, 1, 0]])
: Sum value:  tensor([[-0.1625,  1.9331, -2.3391]])
: torch.Size([2, 1, 3])
: torch.Size([3, 2])
: torch.Size([2, 3])
